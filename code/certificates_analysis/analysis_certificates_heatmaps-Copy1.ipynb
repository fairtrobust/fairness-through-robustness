{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import sys,os\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../../util')\n",
    "\n",
    "import helper as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_labels = {\n",
    "    'cifar10': ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'],\n",
    "    \n",
    "    'utkface': ['0-15', '15-25', '25-40', '40-60', '60+'],\n",
    "\n",
    "    'utkface_race': ['0-15', '15-25', '25-40', '40-60', '60+'],\n",
    "\n",
    "    'utkface_gender': ['0-15', '15-25', '25-40', '40-60', '60+'],\n",
    "    \n",
    "    'adience': ['0-2', '4-6', '8-13', '15-20', '25-32', '38-43', '48-53', '60-'],\n",
    "    \n",
    "    'cifar100': ['beaver', 'dolphin', 'otter', 'seal', 'whale',\n",
    "        'aquarium_fish', 'flatfish', 'ray', 'shark', 'trout',\n",
    "        'orchid', 'poppy', 'rose', 'sunflower', 'tulip',\n",
    "        'bottle', 'bowl', 'can', 'cup', 'plate',\n",
    "        'apple', 'mushroom', 'orange', 'pear', 'sweet_pepper',\n",
    "        'clock', 'keyboard', 'lamp', 'telephone', 'television',\n",
    "        'bed', 'chair', 'couch', 'table', 'wardrobe',\n",
    "        'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach',\n",
    "        'bear', 'leopard', 'lion', 'tiger', 'wolf',\n",
    "        'bridge', 'castle', 'house', 'road', 'skyscraper',\n",
    "        'cloud', 'forest', 'mountain', 'plain', 'sea',\n",
    "        'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo',\n",
    "        'fox', 'porcupine', 'possum', 'raccoon', 'skunk',\n",
    "        'crab', 'lobster', 'snail', 'spider', 'worm',\n",
    "        'baby', 'boy', 'girl', 'man', 'woman',\n",
    "        'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle',\n",
    "        'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel',\n",
    "        'maple_tree', 'oak_tree', 'palm_tree', 'pine_tree', 'willow_tree',\n",
    "        'bicycle', 'bus', 'motorcycle', 'pickup_truck', 'train',\n",
    "        'lawn_mower', 'rocket', 'streetcar', 'tank', 'tractor'],\n",
    "    \n",
    "    'cifar100super': ['aquatic_mammals', 'fish', 'flowers', 'food_containers',\n",
    "        'fruit_and_vegetables', 'household_electrical_devices',\n",
    "        'household_furniture', 'insects', 'large_carnivores',\n",
    "        'large_man-made_outdoor_things', 'large_natural_outdoor_scenes',\n",
    "        'large_omnivores_and_herbivores', 'medium_mammals',\n",
    "        'non-insect_invertebrates', 'people', 'reptiles', 'small_mammals',\n",
    "        'trees', 'vehicles_1', 'vehicles_2']\n",
    "}\n",
    "\n",
    "dataset_to_root_dir = {\n",
    "    'cifar10': '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/cifar10',\n",
    "    'utkface': '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/utkface',\n",
    "    'adience': '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/adience',\n",
    "    'cifar100': '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/cifar100',\n",
    "    'cifar100super': '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/cifar100super'\n",
    "}\n",
    "\n",
    "dataset_to_sens_attrs = {\n",
    "    'cifar10': ['label'],\n",
    "    'utkface': ['label', 'gender', 'race'],\n",
    "    'adience': ['label', 'gender'],\n",
    "    'cifar100': ['label'],\n",
    "    'cifar100super': ['label']\n",
    "}\n",
    "\n",
    "dataset_to_model_names = {\n",
    "    'utkface': ['utk_classifier', 'resnet', 'alexnet', 'vgg', 'densenet', 'squeezenet'],\n",
    "    'cifar10': ['deep_cnn', 'pyramidnet', 'resnet', 'vgg', 'densenet', 'squeezenet'],\n",
    "    'cifar100': ['deep_cnn_cifar100', 'pyramidnet', 'resnet', 'vgg', 'densenet', 'squeezenet'],\n",
    "    'cifar100super': ['deep_cnn_cifar100', 'pyramidnet', 'resnet', 'vgg', 'densenet', 'squeezenet'],\n",
    "    'adience': ['adience_classifier', 'resnet', 'alexnet', 'vgg', 'densenet', 'squeezenet']\n",
    "}\n",
    "\n",
    "sensitive_attrs = {'adience' : ['Female'],\n",
    "                   'utkface_gender': ['Female'],\n",
    "                   'utkface_race': ['white','black','asian','indian','other']\n",
    "                  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Adience'\n",
    "labels = dataset_to_labels[dataset]\n",
    "root_dir = dataset_to_root_dir[dataset]\n",
    "sens_attrs = dataset_to_sens_attrs[dataset]\n",
    "models = dataset_to_model_names[dataset]\n",
    "# lb_files = glob.glob('{}/*'.format(root_dir))\n",
    "lb_files = ['{}/{}_output'.format(root_dir, m) for m in models]\n",
    "lb_files_epoch_0 = ['{}/{}_epoch_0_output'.format(root_dir, m) for m in models]\n",
    "\n",
    "paper_friendly_plots = True\n",
    "\n",
    "COLORS = ['blue', 'red', 'green', 'orange', 'magenta', 'yellow', 'black', 'grey', 'cyan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_obj, datasets, data_loaders = \\\n",
    "    hp.get_data_loder_objects(dataset, ['test'], root_dir='..', **hp.get_loader_kwargs(batch_size=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/adience/adience_classifier_output',\n",
       "  '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/adience/resnet_output',\n",
       "  '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/adience/alexnet_output',\n",
       "  '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/adience/vgg_output',\n",
       "  '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/adience/densenet_output',\n",
       "  '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/adience/squeezenet_output'],\n",
       " ['/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/adience/adience_classifier_epoch_0_output',\n",
       "  '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/adience/resnet_epoch_0_output',\n",
       "  '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/adience/alexnet_epoch_0_output',\n",
       "  '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/adience/vgg_epoch_0_output',\n",
       "  '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/adience/densenet_epoch_0_output',\n",
       "  '/NS/twitter-7/work/vnanda/adversarial_disparity/microsoft-smoothing/code/adience/squeezenet_epoch_0_output'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_files, lb_files_epoch_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_paper_friendly_plots_params():\n",
    "    plt.style.use('seaborn-paper')\n",
    "    plt.rcParams['font.size'] = 10\n",
    "    plt.rcParams['axes.labelsize'] = 22\n",
    "    plt.rcParams['axes.labelweight'] = 'bold'\n",
    "    plt.rcParams['axes.titlesize'] = 15\n",
    "    plt.rcParams['axes.linewidth'] = 1.25\n",
    "    plt.rcParams['xtick.labelsize'] = 16\n",
    "    plt.rcParams['ytick.labelsize'] = 16\n",
    "    plt.rcParams['legend.fontsize'] = 20\n",
    "    plt.rcParams['figure.titlesize'] = 22\n",
    "    plt.rcParams['lines.linewidth'] = 4.0\n",
    "    plt.rcParams['grid.color'] = 'grey'\n",
    "    plt.rcParams['grid.linestyle'] = '--'\n",
    "    plt.rcParams['grid.linewidth'] = 0.25\n",
    "    plt.rcParams['figure.dpi'] = 50\n",
    "    plt.rcParams['savefig.dpi'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps_for_sens_attrs, heatmaps_for_sens_attrs_epoch_0, x_labels, x_labels_epoch_0 = [], [], [], []\n",
    "\n",
    "for sens_attr in sens_attrs:\n",
    "    \n",
    "    if sens_attr == 'gender':\n",
    "\n",
    "        heatmaps_for_sens_attrs.append(np.zeros((len(models), len(ds_obj.genders))))\n",
    "        heatmaps_for_sens_attrs_epoch_0.append(np.zeros((len(models), len(ds_obj.genders))))\n",
    "\n",
    "        x_labels.append([ds_obj.get_image_protected_id_to_label(_id, 'gender') for _id in ds_obj.genders])\n",
    "        x_labels_epoch_0.append([ds_obj.get_image_protected_id_to_label(_id, 'gender') for _id in ds_obj.genders])\n",
    "\n",
    "    elif sens_attr == 'race':\n",
    "        \n",
    "        heatmaps_for_sens_attrs.append(np.zeros((len(models), len(ds_obj.races))))\n",
    "        heatmaps_for_sens_attrs_epoch_0.append(np.zeros((len(models), len(ds_obj.races))))\n",
    "        \n",
    "        x_labels.append([ds_obj.get_image_protected_id_to_label(_id, 'race') for _id in ds_obj.races])\n",
    "        x_labels_epoch_0.append([ds_obj.get_image_protected_id_to_label(_id, 'race') for _id in ds_obj.races])\n",
    "\n",
    "    elif sens_attr == 'label':\n",
    "        \n",
    "        heatmaps_for_sens_attrs.append(np.zeros((len(models), len(ds_obj.classes))))\n",
    "        heatmaps_for_sens_attrs_epoch_0.append(np.zeros((len(models), len(ds_obj.classes))))\n",
    "        \n",
    "        x_labels.append(ds_obj.classes)\n",
    "        x_labels_epoch_0.append(ds_obj.classes)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Sens attr {} not supported!'.format(sens_attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['0-2', '4-6', '8-13', '15-20', '25-32', '38-43', '48-53', '60-'],\n",
       "  ['male', 'female']],\n",
       " [['0-2', '4-6', '8-13', '15-20', '25-32', '38-43', '48-53', '60-'],\n",
       "  ['male', 'female']])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_labels, x_labels_epoch_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689\n",
      "324\n",
      "{0: 12, 1: 80, 2: 18, 3: 5, 4: 144, 5: 48, 7: 17}\n",
      "689\n",
      "324\n",
      "{0: 12, 1: 80, 2: 18, 3: 5, 4: 144, 5: 48, 7: 17}\n",
      "689\n",
      "359\n",
      "{0: 27, 1: 66, 2: 42, 3: 13, 4: 131, 5: 40, 6: 8, 7: 32}\n",
      "689\n",
      "359\n",
      "{0: 27, 1: 66, 2: 42, 3: 13, 4: 131, 5: 40, 6: 8, 7: 32}\n",
      "689\n",
      "318\n",
      "{0: 14, 1: 75, 2: 10, 3: 4, 4: 150, 5: 35, 6: 2, 7: 28}\n",
      "689\n",
      "318\n",
      "{0: 14, 1: 75, 2: 10, 3: 4, 4: 150, 5: 35, 6: 2, 7: 28}\n",
      "689\n",
      "367\n",
      "{0: 20, 1: 63, 2: 44, 3: 13, 4: 155, 5: 39, 6: 8, 7: 25}\n",
      "689\n",
      "367\n",
      "{0: 20, 1: 63, 2: 44, 3: 13, 4: 155, 5: 39, 6: 8, 7: 25}\n",
      "689\n",
      "360\n",
      "{0: 29, 1: 57, 2: 32, 3: 11, 4: 159, 5: 32, 6: 11, 7: 29}\n",
      "689\n",
      "360\n",
      "{0: 29, 1: 57, 2: 32, 3: 11, 4: 159, 5: 32, 6: 11, 7: 29}\n",
      "689\n",
      "341\n",
      "{0: 25, 1: 73, 2: 12, 3: 10, 4: 174, 5: 8, 6: 11, 7: 28}\n",
      "689\n",
      "341\n",
      "{0: 25, 1: 73, 2: 12, 3: 10, 4: 174, 5: 8, 6: 11, 7: 28}\n",
      "594\n",
      "215\n",
      "adience_classifier_epoch_0_output {0: 7, 1: 58, 2: 11, 4: 139}\n",
      "594\n",
      "215\n",
      "adience_classifier_epoch_0_output {0: 7, 1: 58, 2: 11, 4: 139}\n",
      "689\n",
      "343\n",
      "resnet_epoch_0_output {0: 21, 1: 74, 2: 25, 3: 3, 4: 176, 5: 33, 7: 11}\n",
      "689\n",
      "343\n",
      "resnet_epoch_0_output {0: 21, 1: 74, 2: 25, 3: 3, 4: 176, 5: 33, 7: 11}\n",
      "689\n",
      "318\n",
      "alexnet_epoch_0_output {0: 14, 1: 75, 2: 10, 3: 4, 4: 150, 5: 35, 6: 2, 7: 28}\n",
      "689\n",
      "318\n",
      "alexnet_epoch_0_output {0: 14, 1: 75, 2: 10, 3: 4, 4: 150, 5: 35, 6: 2, 7: 28}\n",
      "510\n",
      "254\n",
      "vgg_epoch_0_output {0: 12, 1: 58, 2: 18, 3: 1, 4: 123, 5: 20, 6: 3, 7: 19}\n",
      "510\n",
      "254\n",
      "vgg_epoch_0_output {0: 12, 1: 58, 2: 18, 3: 1, 4: 123, 5: 20, 6: 3, 7: 19}\n",
      "404\n",
      "213\n",
      "densenet_epoch_0_output {0: 21, 1: 48, 2: 12, 4: 112, 5: 13, 7: 7}\n",
      "404\n",
      "213\n",
      "densenet_epoch_0_output {0: 21, 1: 48, 2: 12, 4: 112, 5: 13, 7: 7}\n",
      "689\n",
      "309\n",
      "squeezenet_epoch_0_output {0: 18, 1: 76, 2: 9, 3: 1, 4: 187, 5: 17, 7: 1}\n",
      "689\n",
      "309\n",
      "squeezenet_epoch_0_output {0: 18, 1: 76, 2: 9, 3: 1, 4: 187, 5: 17, 7: 1}\n"
     ]
    }
   ],
   "source": [
    "for model_idx, file in enumerate(lb_files):\n",
    "    for heatmap_idx, sens_attr in enumerate(sens_attrs):\n",
    "        df = pd.read_csv(file, sep='\\t')\n",
    "        print (len(df))\n",
    "        try:\n",
    "            df = df[df['label'] == df['base_prediction']] # take only correct predictions\n",
    "        except:\n",
    "            df = df[df['label'] == df['base']] # take only correct predictions\n",
    "        print (len(df))\n",
    "        unique, counts = np.unique(df['label'].to_numpy(), return_counts=True)\n",
    "        print (dict(zip(unique, counts)))\n",
    "        range_lb = np.linspace(np.min(df['radius']), np.max(df['radius']), 100)\n",
    "        \n",
    "        if paper_friendly_plots:\n",
    "            set_paper_friendly_plots_params()\n",
    "        \n",
    "        for idx, attr in enumerate(np.unique(df[sens_attr].to_numpy())):\n",
    "            minority_radii, majority_radii = df['radius'][df[sens_attr] == attr], \\\n",
    "                df['radius'][df[sens_attr] != attr]\n",
    "            minority_cdf_vals = np.array([np.sum(minority_radii > t)/len(minority_radii) for t in range_lb])\n",
    "            majority_cdf_vals = np.array([np.sum(majority_radii > t)/len(majority_radii) for t in range_lb])\n",
    "            dt = range_lb[1] - range_lb[0]\n",
    "            minority_auc = np.sum(minority_cdf_vals * dt)\n",
    "            majority_auc = np.sum(majority_cdf_vals * dt)\n",
    "            \n",
    "            if sens_attr == 'label':\n",
    "                y_coord = int(attr)\n",
    "            else:\n",
    "                y_coord = ds_obj.get_image_protected_label_to_id(attr, sens_attr)\n",
    "\n",
    "            heatmaps_for_sens_attrs[heatmap_idx][model_idx, y_coord] = (minority_auc - majority_auc)/majority_auc\n",
    "\n",
    "for model_idx, file in enumerate(lb_files_epoch_0):\n",
    "    for heatmap_idx, sens_attr in enumerate(sens_attrs):\n",
    "        df = pd.read_csv(file, sep='\\t')\n",
    "        print (len(df))\n",
    "        try:\n",
    "            df = df[df['label'] == df['base_prediction']] # take only correct predictions\n",
    "        except:\n",
    "            df = df[df['label'] == df['base']] # take only correct predictions\n",
    "        print (len(df))\n",
    "        unique, counts = np.unique(df['label'].to_numpy(), return_counts=True)\n",
    "        print (file.split('/')[-1], dict(zip(unique, counts)))\n",
    "        range_lb = np.linspace(np.min(df['radius']), np.max(df['radius']), 100)\n",
    "        \n",
    "        if paper_friendly_plots:\n",
    "            set_paper_friendly_plots_params()\n",
    "        \n",
    "        for idx, attr in enumerate(np.unique(df[sens_attr].to_numpy())):\n",
    "            minority_radii, majority_radii = df['radius'][df[sens_attr] == attr], \\\n",
    "                df['radius'][df[sens_attr] != attr]\n",
    "            minority_cdf_vals = np.array([np.sum(minority_radii > t)/len(minority_radii) for t in range_lb])\n",
    "            majority_cdf_vals = np.array([np.sum(majority_radii > t)/len(majority_radii) for t in range_lb])\n",
    "            dt = range_lb[1] - range_lb[0]\n",
    "            minority_auc = np.sum(minority_cdf_vals * dt)\n",
    "            majority_auc = np.sum(majority_cdf_vals * dt)\n",
    "            \n",
    "            if sens_attr == 'label':\n",
    "                y_coord = int(attr)\n",
    "            else:\n",
    "                y_coord = ds_obj.get_image_protected_label_to_id(attr, sens_attr)\n",
    "            \n",
    "            sigma = (minority_auc - majority_auc)/majority_auc\n",
    "            heatmaps_for_sens_attrs_epoch_0[heatmap_idx][model_idx, y_coord] = sigma \\\n",
    "                if not np.isnan(sigma) else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmaps_for_sens_attrs[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.04418723,  0.06131513, -0.20665834, -0.26822911,  0.04665226,\n",
       "          0.00365964,  0.        , -0.12663621],\n",
       "        [ 0.91656655, -0.3073543 , -0.1015804 , -0.09825005, -0.01746787,\n",
       "         -0.07239426, -0.43260578,  0.30514157],\n",
       "        [ 0.01387718,  0.0061822 , -0.20503438, -0.15728881,  0.10419667,\n",
       "         -0.15190307, -0.01009803, -0.03733545],\n",
       "        [ 0.10031361, -0.1099014 , -0.3382359 , -0.16910042,  0.29956937,\n",
       "         -0.22453583, -0.39028533,  0.30817232],\n",
       "        [ 0.34475181, -0.19571394, -0.08602015, -0.30644624,  0.18485832,\n",
       "         -0.15518806, -0.0418889 , -0.13228473],\n",
       "        [ 0.24438214, -0.31670719, -0.26033333, -0.24386946,  0.4949874 ,\n",
       "         -0.50257348, -0.64404008, -0.12874147]]),\n",
       " array([[ 0.02479698, -0.02419696],\n",
       "        [-0.1888631 ,  0.23283751],\n",
       "        [-0.00686181,  0.00690922],\n",
       "        [-0.01534866,  0.01558791],\n",
       "        [ 0.02485732, -0.02425442],\n",
       "        [-0.16327495,  0.19513573]])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmaps_for_sens_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(dataset):\n",
    "    labels = dataset_to_labels[dataset]\n",
    "    root_dir = dataset_to_root_dir[dataset]\n",
    "    sens_attrs = dataset_to_sens_attrs[dataset]\n",
    "    models = dataset_to_model_names[dataset]\n",
    "    # lb_files = glob.glob('{}/*'.format(root_dir))\n",
    "    lb_files = ['{}/{}_output'.format(root_dir, m) for m in models]\n",
    "    lb_files_epoch_0 = ['{}/{}_epoch_0_output'.format(root_dir, m) for m in models]\n",
    "\n",
    "    paper_friendly_plots = True\n",
    "\n",
    "    COLORS = ['blue', 'red', 'green', 'orange', 'magenta', 'yellow', 'black', 'grey', 'cyan']\n",
    "\n",
    "    ds_obj, datasets, data_loaders = \\\n",
    "        hp.get_data_loder_objects(dataset, ['test'], root_dir='..', **hp.get_loader_kwargs(batch_size=100))  \n",
    "\n",
    "    heatmaps_for_sens_attrs, heatmaps_for_sens_attrs_epoch_0, x_labels, x_labels_epoch_0 = [], [], [], []\n",
    "\n",
    "    for sens_attr in sens_attrs:\n",
    "\n",
    "        if sens_attr == 'gender':\n",
    "\n",
    "            heatmaps_for_sens_attrs.append(np.zeros((len(models), len(ds_obj.genders))))\n",
    "            heatmaps_for_sens_attrs_epoch_0.append(np.zeros((len(models), len(ds_obj.genders))))\n",
    "\n",
    "            x_labels.append([ds_obj.get_image_protected_id_to_label(_id, 'gender') for _id in ds_obj.genders])\n",
    "            x_labels_epoch_0.append([ds_obj.get_image_protected_id_to_label(_id, 'gender') for _id in ds_obj.genders])\n",
    "\n",
    "        elif sens_attr == 'race':\n",
    "\n",
    "            heatmaps_for_sens_attrs.append(np.zeros((len(models), len(ds_obj.races))))\n",
    "            heatmaps_for_sens_attrs_epoch_0.append(np.zeros((len(models), len(ds_obj.races))))\n",
    "\n",
    "            x_labels.append([ds_obj.get_image_protected_id_to_label(_id, 'race') for _id in ds_obj.races])\n",
    "            x_labels_epoch_0.append([ds_obj.get_image_protected_id_to_label(_id, 'race') for _id in ds_obj.races])\n",
    "\n",
    "        elif sens_attr == 'label':\n",
    "\n",
    "            heatmaps_for_sens_attrs.append(np.zeros((len(models), len(ds_obj.classes))))\n",
    "            heatmaps_for_sens_attrs_epoch_0.append(np.zeros((len(models), len(ds_obj.classes))))\n",
    "\n",
    "            x_labels.append(ds_obj.classes)\n",
    "            x_labels_epoch_0.append(ds_obj.classes)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Sens attr {} not supported!'.format(sens_attr))\n",
    "\n",
    "\n",
    "    for model_idx, file in enumerate(lb_files):\n",
    "        for heatmap_idx, sens_attr in enumerate(sens_attrs):\n",
    "            df = pd.read_csv(file, sep='\\t')\n",
    "            print (len(df))\n",
    "            try:\n",
    "                df = df[df['label'] == df['base_prediction']] # take only correct predictions\n",
    "            except:\n",
    "                df = df[df['label'] == df['base']] # take only correct predictions\n",
    "            print (len(df))\n",
    "            unique, counts = np.unique(df['label'].to_numpy(), return_counts=True)\n",
    "            print (dict(zip(unique, counts)))\n",
    "            range_lb = np.linspace(np.min(df['radius']), np.max(df['radius']), 100)\n",
    "\n",
    "            if paper_friendly_plots:\n",
    "                set_paper_friendly_plots_params()\n",
    "\n",
    "            for idx, attr in enumerate(np.unique(df[sens_attr].to_numpy())):\n",
    "                minority_radii, majority_radii = df['radius'][df[sens_attr] == attr], \\\n",
    "                    df['radius'][df[sens_attr] != attr]\n",
    "                minority_cdf_vals = np.array([np.sum(minority_radii > t)/len(minority_radii) for t in range_lb])\n",
    "                majority_cdf_vals = np.array([np.sum(majority_radii > t)/len(majority_radii) for t in range_lb])\n",
    "                dt = range_lb[1] - range_lb[0]\n",
    "                minority_auc = np.sum(minority_cdf_vals * dt)\n",
    "                majority_auc = np.sum(majority_cdf_vals * dt)\n",
    "\n",
    "                if sens_attr == 'label':\n",
    "                    y_coord = int(attr)\n",
    "                else:\n",
    "                    y_coord = ds_obj.get_image_protected_label_to_id(attr, sens_attr)\n",
    "\n",
    "                heatmaps_for_sens_attrs[heatmap_idx][model_idx, y_coord] = (minority_auc - majority_auc)/majority_auc\n",
    "\n",
    "    for model_idx, file in enumerate(lb_files_epoch_0):\n",
    "        for heatmap_idx, sens_attr in enumerate(sens_attrs):\n",
    "            df = pd.read_csv(file, sep='\\t')\n",
    "            print (len(df))\n",
    "            try:\n",
    "                df = df[df['label'] == df['base_prediction']] # take only correct predictions\n",
    "            except:\n",
    "                df = df[df['label'] == df['base']] # take only correct predictions\n",
    "            print (len(df))\n",
    "            unique, counts = np.unique(df['label'].to_numpy(), return_counts=True)\n",
    "            print (file.split('/')[-1], dict(zip(unique, counts)))\n",
    "            range_lb = np.linspace(np.min(df['radius']), np.max(df['radius']), 100)\n",
    "\n",
    "            if paper_friendly_plots:\n",
    "                set_paper_friendly_plots_params()\n",
    "\n",
    "            for idx, attr in enumerate(np.unique(df[sens_attr].to_numpy())):\n",
    "                minority_radii, majority_radii = df['radius'][df[sens_attr] == attr], \\\n",
    "                    df['radius'][df[sens_attr] != attr]\n",
    "                minority_cdf_vals = np.array([np.sum(minority_radii > t)/len(minority_radii) for t in range_lb])\n",
    "                majority_cdf_vals = np.array([np.sum(majority_radii > t)/len(majority_radii) for t in range_lb])\n",
    "                dt = range_lb[1] - range_lb[0]\n",
    "                minority_auc = np.sum(minority_cdf_vals * dt)\n",
    "                majority_auc = np.sum(majority_cdf_vals * dt)\n",
    "\n",
    "                if sens_attr == 'label':\n",
    "                    y_coord = int(attr)\n",
    "                else:\n",
    "                    y_coord = ds_obj.get_image_protected_label_to_id(attr, sens_attr)\n",
    "\n",
    "                sigma = (minority_auc - majority_auc)/majority_auc\n",
    "                heatmaps_for_sens_attrs_epoch_0[heatmap_idx][model_idx, y_coord] = sigma \\\n",
    "                    if not np.isnan(sigma) else 0.\n",
    "            \n",
    "    return heatmaps_for_sens_attrs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ds(ds_name, models, classes, attack):\n",
    "\n",
    "    a = len(classes[ds_name.lower()])\n",
    "    b = len(models)\n",
    "\n",
    "    best_arr = np.zeros((a,b))\n",
    "    frst_arr = np.zeros((a,b))\n",
    "    \n",
    "    for i,model in enumerate(models):\n",
    "        ### find the middle epoch of training \n",
    "        trained_models = glob.glob('../../{}/model_weights/{}'.format(ds_name, \n",
    "                                                           '{}_epoch_*[0-9]_lr_*.pth'.format(model)))\n",
    "        directory = '../plots/{}/{}/{}'.format(ds_name,model,attack)\n",
    "\n",
    "        for j,sens_attr in enumerate(classes[ds_name.lower()]):\n",
    "\n",
    "\n",
    "            best_cdf, mid_cdf, fst_cdf = None, None, None\n",
    "\n",
    "            best_fn_w_epoch  = '{}/cdfs_{}_epoch_best.dat'.format(directory,sens_attr)\n",
    "            best_fn_wo_epoch = '{}/cdfs_{}.dat'.format(directory,sens_attr)\n",
    "            if os.path.exists(best_fn_w_epoch):\n",
    "                with open(best_fn_w_epoch,'rb') as f:\n",
    "                    best_cdf = pickle.load(f)\n",
    "            elif os.path.exists(best_fn_wo_epoch):\n",
    "                with open(best_fn_wo_epoch,'rb') as f:\n",
    "                    best_cdf = pickle.load(f)\n",
    "\n",
    "            if best_cdf:\n",
    "                dt = (best_cdf['taus'][1]-best_cdf['taus'][0])\n",
    "                minority = sum(best_cdf['minority']*dt)\n",
    "                majority = sum(best_cdf['majority']*dt)\n",
    "\n",
    "                best_arr[j,i] = (minority-majority)/majority\n",
    "\n",
    "\n",
    "            first_fn_w_epoch = '{}/cdfs_{}_epoch_{}.dat'.format(directory,sens_attr,'0')\n",
    "            if os.path.exists(first_fn_w_epoch):\n",
    "                with open(first_fn_w_epoch,'rb') as f:\n",
    "                    fst_cdf = pickle.load(f)\n",
    "\n",
    "            if fst_cdf:\n",
    "                dt = (fst_cdf['taus'][1]-fst_cdf['taus'][0])\n",
    "                minority = sum(fst_cdf['minority']*dt)\n",
    "                majority = sum(fst_cdf['majority']*dt)\n",
    "\n",
    "                frst_arr[j,i] = (minority-majority)/majority\n",
    "                \n",
    "    return best_arr, frst_arr\n",
    "\n",
    "df = 'DeepFool'\n",
    "cw = 'CarliniWagner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "1726\n",
      "{0: 158, 1: 192, 2: 166, 3: 168, 4: 186, 5: 140, 6: 183, 7: 170, 8: 182, 9: 181}\n",
      "2000\n",
      "1719\n",
      "{0: 170, 1: 195, 2: 168, 3: 150, 4: 174, 5: 143, 6: 171, 7: 181, 8: 184, 9: 183}\n",
      "2000\n",
      "1665\n",
      "{0: 160, 1: 185, 2: 173, 3: 157, 4: 172, 5: 133, 6: 167, 7: 177, 8: 174, 9: 167}\n",
      "2000\n",
      "1788\n",
      "{0: 164, 1: 202, 2: 186, 3: 165, 4: 182, 5: 146, 6: 183, 7: 185, 8: 186, 9: 189}\n",
      "2000\n",
      "1673\n",
      "{0: 158, 1: 191, 2: 154, 3: 142, 4: 169, 5: 146, 6: 182, 7: 178, 8: 179, 9: 174}\n",
      "2000\n",
      "1539\n",
      "{0: 151, 1: 166, 2: 133, 3: 130, 4: 165, 5: 108, 6: 169, 7: 159, 8: 177, 9: 181}\n",
      "2000\n",
      "197\n",
      "deep_cnn_epoch_0_output {4: 197}\n",
      "160\n",
      "89\n",
      "pyramidnet_epoch_0_output {0: 3, 1: 10, 2: 5, 3: 5, 4: 5, 5: 9, 6: 13, 7: 11, 8: 10, 9: 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/NS/twitter-7/work/vnanda/miniconda3/envs/adv_disparity/lib/python3.7/site-packages/ipykernel_launcher.py:101: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "1480\n",
      "resnet_epoch_0_output {0: 143, 1: 167, 2: 121, 3: 142, 4: 159, 5: 99, 6: 156, 7: 158, 8: 173, 9: 162}\n",
      "877\n",
      "702\n",
      "vgg_epoch_0_output {0: 65, 1: 80, 2: 62, 3: 45, 4: 87, 5: 53, 6: 78, 7: 77, 8: 77, 9: 78}\n",
      "2000\n",
      "1558\n",
      "densenet_epoch_0_output {0: 158, 1: 188, 2: 139, 3: 114, 4: 167, 5: 112, 6: 165, 7: 171, 8: 175, 9: 169}\n",
      "2000\n",
      "205\n",
      "squeezenet_epoch_0_output {7: 205}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/NS/twitter-7/work/vnanda/miniconda3/envs/adv_disparity/lib/python3.7/site-packages/ipykernel_launcher.py:101: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "2000\n",
      "1193\n",
      "{0: 23, 1: 19, 2: 9, 3: 6, 4: 10, 5: 5, 6: 9, 7: 6, 8: 10, 9: 20, 10: 8, 11: 5, 12: 21, 13: 5, 14: 7, 15: 11, 16: 22, 17: 12, 18: 10, 19: 7, 20: 14, 21: 16, 22: 10, 23: 14, 24: 16, 25: 9, 26: 10, 27: 6, 28: 15, 29: 10, 30: 14, 31: 10, 32: 11, 33: 7, 34: 10, 35: 15, 36: 12, 37: 11, 38: 8, 39: 15, 40: 10, 41: 17, 42: 12, 43: 17, 44: 6, 45: 9, 46: 8, 47: 20, 48: 18, 49: 18, 50: 7, 51: 7, 52: 13, 53: 19, 54: 15, 55: 8, 56: 14, 57: 17, 58: 14, 59: 7, 60: 20, 61: 17, 62: 8, 63: 11, 64: 7, 65: 8, 66: 18, 67: 10, 68: 16, 69: 16, 70: 22, 71: 16, 72: 4, 73: 7, 74: 7, 75: 12, 76: 15, 77: 12, 78: 8, 79: 18, 80: 7, 81: 9, 82: 24, 83: 9, 84: 9, 85: 8, 86: 11, 87: 10, 88: 12, 89: 10, 90: 11, 91: 17, 92: 11, 93: 6, 94: 16, 95: 10, 96: 12, 97: 11, 98: 8, 99: 16}\n",
      "2000\n",
      "1133\n",
      "{0: 23, 1: 16, 2: 9, 3: 6, 4: 10, 5: 8, 6: 8, 7: 10, 8: 10, 9: 16, 10: 8, 11: 8, 12: 20, 13: 9, 14: 9, 15: 11, 16: 22, 17: 9, 18: 4, 19: 7, 20: 12, 21: 15, 22: 13, 23: 12, 24: 13, 25: 8, 26: 7, 27: 7, 28: 12, 29: 8, 30: 4, 31: 6, 32: 10, 33: 5, 34: 10, 35: 8, 36: 9, 37: 11, 38: 4, 39: 12, 40: 10, 41: 20, 42: 15, 43: 13, 44: 5, 45: 15, 46: 9, 47: 16, 48: 17, 49: 13, 50: 8, 51: 11, 52: 7, 53: 20, 54: 11, 55: 6, 56: 12, 57: 15, 58: 14, 59: 13, 60: 20, 61: 15, 62: 8, 63: 8, 64: 7, 65: 8, 66: 16, 67: 11, 68: 15, 69: 15, 70: 18, 71: 15, 72: 4, 73: 5, 74: 8, 75: 12, 76: 14, 77: 15, 78: 10, 79: 18, 80: 6, 81: 14, 82: 22, 83: 9, 84: 16, 85: 7, 86: 9, 87: 15, 88: 17, 89: 12, 90: 9, 91: 15, 92: 6, 93: 7, 94: 13, 95: 9, 96: 14, 97: 10, 98: 8, 99: 14}\n",
      "2000\n",
      "1129\n",
      "{0: 21, 1: 15, 2: 6, 3: 8, 4: 8, 5: 6, 6: 7, 7: 9, 8: 11, 9: 13, 10: 9, 11: 7, 12: 19, 13: 9, 14: 11, 15: 10, 16: 24, 17: 11, 18: 8, 19: 9, 20: 13, 21: 15, 22: 10, 23: 20, 24: 18, 25: 7, 26: 10, 27: 7, 28: 11, 29: 9, 30: 7, 31: 6, 32: 11, 33: 6, 34: 12, 35: 5, 36: 8, 37: 11, 38: 8, 39: 16, 40: 14, 41: 17, 42: 13, 43: 15, 44: 4, 45: 10, 46: 7, 47: 18, 48: 17, 49: 16, 50: 11, 51: 6, 52: 11, 53: 19, 54: 12, 55: 11, 56: 15, 57: 14, 58: 12, 59: 11, 60: 16, 61: 14, 62: 8, 63: 9, 64: 10, 65: 6, 66: 17, 67: 11, 68: 14, 69: 16, 70: 13, 71: 12, 72: 2, 73: 9, 74: 11, 75: 9, 76: 15, 77: 12, 78: 10, 79: 20, 80: 9, 81: 6, 82: 23, 83: 10, 84: 9, 85: 8, 86: 9, 87: 11, 88: 13, 89: 14, 90: 13, 91: 13, 92: 7, 93: 6, 94: 14, 95: 11, 96: 5, 97: 5, 98: 10, 99: 15}\n",
      "1168\n",
      "787\n",
      "{0: 18, 1: 9, 2: 4, 3: 5, 4: 5, 5: 5, 6: 4, 7: 5, 8: 7, 9: 13, 10: 5, 11: 9, 12: 16, 13: 4, 14: 6, 15: 11, 16: 16, 17: 7, 18: 5, 19: 7, 20: 10, 21: 11, 22: 8, 23: 8, 24: 8, 25: 12, 26: 4, 27: 5, 28: 9, 29: 5, 30: 7, 31: 6, 32: 3, 33: 4, 34: 6, 35: 4, 36: 5, 37: 12, 38: 6, 39: 10, 40: 7, 41: 19, 42: 7, 43: 9, 44: 7, 45: 3, 46: 8, 47: 10, 48: 10, 49: 16, 50: 6, 51: 4, 52: 8, 53: 12, 54: 10, 55: 4, 56: 10, 57: 9, 58: 11, 59: 9, 60: 12, 61: 10, 62: 3, 63: 7, 64: 6, 65: 6, 66: 16, 67: 11, 68: 9, 69: 11, 70: 9, 71: 9, 72: 1, 73: 6, 74: 7, 75: 6, 76: 7, 77: 8, 78: 9, 79: 9, 80: 5, 81: 5, 82: 12, 83: 3, 84: 7, 85: 6, 86: 4, 87: 10, 88: 9, 89: 9, 90: 9, 91: 9, 92: 5, 93: 6, 94: 11, 95: 9, 96: 6, 97: 4, 98: 6, 99: 7}\n",
      "109\n",
      "67\n",
      "{2: 1, 6: 1, 9: 2, 10: 1, 12: 2, 16: 2, 19: 1, 20: 2, 21: 1, 22: 2, 23: 2, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 32: 2, 36: 1, 38: 1, 39: 1, 40: 3, 41: 1, 42: 1, 43: 1, 47: 1, 53: 2, 57: 1, 59: 1, 60: 1, 63: 1, 64: 2, 66: 4, 68: 2, 69: 2, 70: 1, 71: 2, 78: 1, 79: 1, 85: 2, 89: 2, 90: 1, 91: 2, 94: 1, 95: 1, 96: 1, 99: 2}\n",
      "717\n",
      "285\n",
      "{0: 8, 1: 7, 2: 2, 4: 1, 6: 1, 8: 2, 9: 5, 10: 3, 11: 4, 12: 6, 13: 2, 14: 2, 15: 4, 16: 7, 17: 3, 18: 1, 19: 1, 20: 4, 21: 9, 22: 2, 23: 4, 24: 2, 25: 1, 26: 3, 28: 2, 29: 3, 30: 1, 32: 2, 33: 2, 34: 1, 36: 4, 37: 2, 39: 3, 40: 3, 41: 12, 42: 4, 43: 5, 44: 1, 45: 1, 46: 4, 47: 5, 48: 3, 49: 4, 50: 1, 51: 1, 52: 3, 53: 7, 54: 2, 56: 2, 57: 3, 58: 2, 59: 3, 60: 7, 61: 3, 63: 2, 64: 3, 65: 1, 66: 5, 67: 4, 68: 7, 69: 7, 70: 6, 71: 5, 73: 3, 74: 2, 75: 2, 76: 4, 78: 2, 79: 2, 81: 2, 82: 5, 84: 1, 85: 2, 86: 2, 87: 5, 88: 4, 89: 2, 91: 5, 92: 2, 93: 2, 94: 5, 95: 5, 96: 2, 98: 1, 99: 5}\n",
      "1661\n",
      "31\n",
      "deep_cnn_cifar100_epoch_0_output {54: 4, 60: 20, 93: 7}\n",
      "131\n",
      "19\n",
      "pyramidnet_epoch_0_output {12: 1, 20: 1, 23: 2, 24: 1, 27: 1, 35: 1, 37: 2, 41: 1, 42: 1, 47: 1, 66: 1, 68: 1, 71: 3, 79: 1, 82: 1}\n",
      "2000\n",
      "885\n",
      "resnet_epoch_0_output {0: 25, 1: 7, 2: 9, 3: 8, 4: 2, 5: 3, 6: 6, 7: 5, 8: 6, 9: 15, 10: 6, 11: 9, 12: 10, 13: 5, 14: 9, 15: 7, 16: 20, 17: 7, 18: 8, 19: 3, 20: 7, 21: 12, 22: 7, 23: 19, 24: 11, 25: 7, 26: 5, 27: 7, 28: 10, 29: 9, 30: 4, 31: 6, 32: 7, 33: 8, 34: 11, 35: 3, 36: 8, 37: 4, 38: 1, 39: 17, 40: 3, 41: 14, 42: 13, 43: 10, 44: 7, 45: 6, 47: 11, 48: 16, 49: 7, 50: 4, 51: 6, 52: 11, 53: 18, 54: 11, 55: 4, 56: 16, 57: 12, 58: 6, 59: 8, 60: 19, 61: 17, 62: 3, 63: 5, 64: 6, 65: 5, 66: 8, 67: 10, 68: 15, 69: 14, 70: 14, 71: 13, 73: 9, 74: 7, 75: 11, 76: 14, 77: 14, 78: 7, 79: 16, 80: 2, 81: 9, 82: 23, 83: 8, 84: 2, 85: 3, 86: 8, 87: 14, 88: 5, 89: 7, 90: 3, 91: 10, 92: 4, 93: 3, 94: 13, 95: 9, 96: 12, 97: 6, 98: 8, 99: 13}\n",
      "1186\n",
      "608\n",
      "vgg_epoch_0_output {0: 19, 1: 5, 2: 2, 3: 2, 4: 3, 5: 2, 6: 3, 7: 5, 8: 6, 9: 11, 10: 5, 11: 7, 12: 9, 13: 2, 14: 4, 15: 7, 16: 14, 17: 10, 18: 4, 19: 3, 20: 7, 21: 12, 22: 4, 23: 10, 24: 2, 25: 5, 26: 6, 27: 7, 28: 8, 29: 5, 30: 5, 31: 2, 32: 5, 33: 3, 34: 3, 36: 3, 37: 10, 38: 6, 39: 9, 40: 6, 41: 15, 42: 6, 43: 7, 44: 2, 45: 5, 46: 9, 47: 9, 48: 11, 49: 18, 50: 2, 51: 4, 52: 7, 53: 12, 54: 9, 55: 2, 56: 10, 57: 5, 58: 10, 59: 3, 60: 11, 61: 7, 62: 2, 63: 7, 64: 4, 65: 2, 66: 9, 67: 1, 68: 8, 69: 8, 70: 6, 71: 6, 73: 5, 74: 2, 75: 7, 76: 4, 77: 5, 78: 7, 79: 9, 81: 6, 82: 7, 83: 2, 84: 7, 85: 6, 86: 4, 87: 8, 88: 7, 89: 4, 90: 6, 91: 6, 93: 2, 94: 11, 95: 10, 96: 6, 97: 4, 98: 7, 99: 8}\n",
      "109\n",
      "48\n",
      "densenet_epoch_0_output {6: 1, 9: 2, 12: 2, 16: 1, 22: 2, 23: 1, 24: 1, 25: 1, 27: 1, 28: 1, 32: 1, 36: 1, 39: 1, 40: 2, 41: 1, 42: 1, 43: 1, 46: 1, 53: 2, 58: 1, 63: 1, 66: 1, 68: 2, 69: 1, 70: 1, 71: 3, 78: 1, 79: 1, 85: 2, 86: 1, 89: 1, 90: 1, 91: 2, 94: 1, 95: 1, 96: 1, 99: 2}\n",
      "716\n",
      "69\n",
      "squeezenet_epoch_0_output {0: 3, 7: 1, 8: 1, 9: 4, 16: 3, 20: 2, 24: 2, 28: 1, 30: 1, 42: 4, 53: 10, 59: 6, 60: 7, 64: 1, 71: 3, 73: 1, 76: 3, 82: 1, 87: 2, 89: 1, 92: 1, 94: 5, 95: 2, 97: 1, 98: 2, 99: 1}\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "2000\n",
      "1422\n",
      "{0: 72, 1: 68, 2: 84, 3: 80, 4: 79, 5: 68, 6: 71, 7: 56, 8: 65, 9: 83, 10: 90, 11: 71, 12: 51, 13: 80, 14: 90, 15: 46, 16: 58, 17: 90, 18: 62, 19: 58}\n",
      "2000\n",
      "1349\n",
      "{0: 49, 1: 75, 2: 71, 3: 72, 4: 86, 5: 58, 6: 68, 7: 53, 8: 64, 9: 84, 10: 78, 11: 60, 12: 55, 13: 74, 14: 76, 15: 52, 16: 59, 17: 88, 18: 65, 19: 62}\n",
      "2000\n",
      "1330\n",
      "{0: 49, 1: 67, 2: 77, 3: 84, 4: 75, 5: 67, 6: 61, 7: 55, 8: 60, 9: 78, 10: 78, 11: 64, 12: 56, 13: 66, 14: 78, 15: 51, 16: 46, 17: 87, 18: 66, 19: 65}\n",
      "1164\n",
      "905\n",
      "{0: 41, 1: 42, 2: 49, 3: 60, 4: 50, 5: 40, 6: 51, 7: 28, 8: 39, 9: 56, 10: 54, 11: 43, 12: 32, 13: 34, 14: 58, 15: 41, 16: 37, 17: 56, 18: 46, 19: 48}\n",
      "108\n",
      "78\n",
      "{0: 3, 1: 3, 2: 1, 3: 5, 4: 5, 5: 7, 6: 4, 7: 3, 8: 2, 9: 6, 10: 4, 11: 3, 12: 6, 13: 6, 14: 3, 15: 2, 16: 2, 17: 3, 18: 3, 19: 7}\n",
      "707\n",
      "401\n",
      "{0: 15, 1: 29, 2: 20, 3: 22, 4: 27, 5: 19, 6: 14, 7: 15, 8: 12, 9: 33, 10: 30, 11: 21, 12: 12, 13: 10, 14: 28, 15: 11, 16: 14, 17: 26, 18: 14, 19: 29}\n",
      "1599\n",
      "127\n",
      "deep_cnn_cifar100_epoch_0_output {0: 12, 2: 35, 4: 1, 8: 3, 9: 73, 15: 3}\n",
      "127\n",
      "31\n",
      "pyramidnet_epoch_0_output {0: 1, 1: 1, 4: 1, 5: 2, 6: 2, 7: 2, 8: 3, 9: 2, 10: 5, 11: 1, 12: 2, 14: 2, 16: 2, 17: 3, 19: 2}\n",
      "2000\n",
      "1137\n",
      "resnet_epoch_0_output {0: 46, 1: 62, 2: 80, 3: 65, 4: 66, 5: 60, 6: 58, 7: 50, 8: 51, 9: 62, 10: 74, 11: 49, 12: 42, 13: 34, 14: 72, 15: 40, 16: 33, 17: 87, 18: 53, 19: 53}\n",
      "1113\n",
      "763\n",
      "vgg_epoch_0_output {0: 27, 1: 34, 2: 46, 3: 55, 4: 40, 5: 29, 6: 43, 7: 32, 8: 34, 9: 46, 10: 46, 11: 37, 12: 24, 13: 25, 14: 52, 15: 37, 16: 31, 17: 51, 18: 36, 19: 38}\n",
      "108\n",
      "72\n",
      "densenet_epoch_0_output {0: 1, 1: 4, 2: 1, 3: 4, 4: 4, 5: 8, 6: 3, 7: 3, 8: 3, 9: 5, 10: 6, 12: 3, 13: 7, 14: 3, 15: 4, 16: 2, 17: 3, 18: 2, 19: 6}\n",
      "708\n",
      "191\n",
      "squeezenet_epoch_0_output {0: 6, 1: 8, 2: 11, 3: 13, 4: 25, 5: 7, 6: 15, 7: 5, 9: 27, 10: 15, 11: 22, 14: 12, 16: 1, 17: 21, 18: 3}\n",
      "689\n",
      "324\n",
      "{0: 12, 1: 80, 2: 18, 3: 5, 4: 144, 5: 48, 7: 17}\n",
      "689\n",
      "324\n",
      "{0: 12, 1: 80, 2: 18, 3: 5, 4: 144, 5: 48, 7: 17}\n",
      "689\n",
      "359\n",
      "{0: 27, 1: 66, 2: 42, 3: 13, 4: 131, 5: 40, 6: 8, 7: 32}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689\n",
      "359\n",
      "{0: 27, 1: 66, 2: 42, 3: 13, 4: 131, 5: 40, 6: 8, 7: 32}\n",
      "689\n",
      "318\n",
      "{0: 14, 1: 75, 2: 10, 3: 4, 4: 150, 5: 35, 6: 2, 7: 28}\n",
      "689\n",
      "318\n",
      "{0: 14, 1: 75, 2: 10, 3: 4, 4: 150, 5: 35, 6: 2, 7: 28}\n",
      "689\n",
      "367\n",
      "{0: 20, 1: 63, 2: 44, 3: 13, 4: 155, 5: 39, 6: 8, 7: 25}\n",
      "689\n",
      "367\n",
      "{0: 20, 1: 63, 2: 44, 3: 13, 4: 155, 5: 39, 6: 8, 7: 25}\n",
      "689\n",
      "360\n",
      "{0: 29, 1: 57, 2: 32, 3: 11, 4: 159, 5: 32, 6: 11, 7: 29}\n",
      "689\n",
      "360\n",
      "{0: 29, 1: 57, 2: 32, 3: 11, 4: 159, 5: 32, 6: 11, 7: 29}\n",
      "689\n",
      "341\n",
      "{0: 25, 1: 73, 2: 12, 3: 10, 4: 174, 5: 8, 6: 11, 7: 28}\n",
      "689\n",
      "341\n",
      "{0: 25, 1: 73, 2: 12, 3: 10, 4: 174, 5: 8, 6: 11, 7: 28}\n",
      "613\n",
      "229\n",
      "adience_classifier_epoch_0_output {0: 7, 1: 58, 2: 11, 4: 153}\n",
      "613\n",
      "229\n",
      "adience_classifier_epoch_0_output {0: 7, 1: 58, 2: 11, 4: 153}\n",
      "689\n",
      "343\n",
      "resnet_epoch_0_output {0: 21, 1: 74, 2: 25, 3: 3, 4: 176, 5: 33, 7: 11}\n",
      "689\n",
      "343\n",
      "resnet_epoch_0_output {0: 21, 1: 74, 2: 25, 3: 3, 4: 176, 5: 33, 7: 11}\n",
      "689\n",
      "318\n",
      "alexnet_epoch_0_output {0: 14, 1: 75, 2: 10, 3: 4, 4: 150, 5: 35, 6: 2, 7: 28}\n",
      "689\n",
      "318\n",
      "alexnet_epoch_0_output {0: 14, 1: 75, 2: 10, 3: 4, 4: 150, 5: 35, 6: 2, 7: 28}\n",
      "530\n",
      "259\n",
      "vgg_epoch_0_output {0: 12, 1: 60, 2: 20, 3: 1, 4: 123, 5: 21, 6: 3, 7: 19}\n",
      "530\n",
      "259\n",
      "vgg_epoch_0_output {0: 12, 1: 60, 2: 20, 3: 1, 4: 123, 5: 21, 6: 3, 7: 19}\n",
      "418\n",
      "214\n",
      "densenet_epoch_0_output {0: 21, 1: 48, 2: 13, 4: 112, 5: 13, 7: 7}\n",
      "418\n",
      "214\n",
      "densenet_epoch_0_output {0: 21, 1: 48, 2: 13, 4: 112, 5: 13, 7: 7}\n",
      "689\n",
      "309\n",
      "squeezenet_epoch_0_output {0: 18, 1: 76, 2: 9, 3: 1, 4: 187, 5: 17, 7: 1}\n",
      "689\n",
      "309\n",
      "squeezenet_epoch_0_output {0: 18, 1: 76, 2: 9, 3: 1, 4: 187, 5: 17, 7: 1}\n",
      "949\n",
      "624\n",
      "{0: 139, 1: 40, 2: 314, 3: 60, 4: 71}\n",
      "949\n",
      "624\n",
      "{0: 139, 1: 40, 2: 314, 3: 60, 4: 71}\n",
      "949\n",
      "624\n",
      "{0: 139, 1: 40, 2: 314, 3: 60, 4: 71}\n",
      "950\n",
      "672\n",
      "{0.0: 147, 1.0: 56, 2.0: 304, 3.0: 91, 4.0: 74}\n",
      "950\n",
      "672\n",
      "{0.0: 147, 1.0: 56, 2.0: 304, 3.0: 91, 4.0: 74}\n",
      "950\n",
      "672\n",
      "{0.0: 147, 1.0: 56, 2.0: 304, 3.0: 91, 4.0: 74}\n",
      "949\n",
      "664\n",
      "{0: 144, 1: 76, 2: 284, 3: 93, 4: 67}\n",
      "949\n",
      "664\n",
      "{0: 144, 1: 76, 2: 284, 3: 93, 4: 67}\n",
      "949\n",
      "664\n",
      "{0: 144, 1: 76, 2: 284, 3: 93, 4: 67}\n",
      "949\n",
      "667\n",
      "{0: 145, 1: 46, 2: 302, 3: 100, 4: 74}\n",
      "949\n",
      "667\n",
      "{0: 145, 1: 46, 2: 302, 3: 100, 4: 74}\n",
      "949\n",
      "667\n",
      "{0: 145, 1: 46, 2: 302, 3: 100, 4: 74}\n",
      "949\n",
      "666\n",
      "{0: 145, 1: 57, 2: 290, 3: 92, 4: 82}\n",
      "949\n",
      "666\n",
      "{0: 145, 1: 57, 2: 290, 3: 92, 4: 82}\n",
      "949\n",
      "666\n",
      "{0: 145, 1: 57, 2: 290, 3: 92, 4: 82}\n",
      "949\n",
      "641\n",
      "{0: 145, 1: 67, 2: 236, 3: 118, 4: 75}\n",
      "949\n",
      "641\n",
      "{0: 145, 1: 67, 2: 236, 3: 118, 4: 75}\n",
      "949\n",
      "641\n",
      "{0: 145, 1: 67, 2: 236, 3: 118, 4: 75}\n",
      "949\n",
      "460\n",
      "utk_classifier_epoch_0_output {0: 130, 2: 313, 3: 3, 4: 14}\n",
      "949\n",
      "460\n",
      "utk_classifier_epoch_0_output {0: 130, 2: 313, 3: 3, 4: 14}\n",
      "949\n",
      "460\n",
      "utk_classifier_epoch_0_output {0: 130, 2: 313, 3: 3, 4: 14}\n",
      "828\n",
      "552\n",
      "resnet_epoch_0_output {0: 119, 1: 19, 2: 263, 3: 86, 4: 65}\n",
      "828\n",
      "552\n",
      "resnet_epoch_0_output {0: 119, 1: 19, 2: 263, 3: 86, 4: 65}\n",
      "828\n",
      "552\n",
      "resnet_epoch_0_output {0: 119, 1: 19, 2: 263, 3: 86, 4: 65}\n",
      "949\n",
      "605\n",
      "alexnet_epoch_0_output {0: 138, 1: 18, 2: 332, 3: 62, 4: 55}\n",
      "949\n",
      "605\n",
      "alexnet_epoch_0_output {0: 138, 1: 18, 2: 332, 3: 62, 4: 55}\n",
      "949\n",
      "605\n",
      "alexnet_epoch_0_output {0: 138, 1: 18, 2: 332, 3: 62, 4: 55}\n",
      "287\n",
      "188\n",
      "vgg_epoch_0_output {0: 36, 1: 7, 2: 92, 3: 24, 4: 29}\n",
      "287\n",
      "188\n",
      "vgg_epoch_0_output {0: 36, 1: 7, 2: 92, 3: 24, 4: 29}\n",
      "287\n",
      "188\n",
      "vgg_epoch_0_output {0: 36, 1: 7, 2: 92, 3: 24, 4: 29}\n",
      "462\n",
      "309\n",
      "densenet_epoch_0_output {0: 66, 1: 11, 2: 150, 3: 50, 4: 32}\n",
      "462\n",
      "309\n",
      "densenet_epoch_0_output {0: 66, 1: 11, 2: 150, 3: 50, 4: 32}\n",
      "462\n",
      "309\n",
      "densenet_epoch_0_output {0: 66, 1: 11, 2: 150, 3: 50, 4: 32}\n",
      "755\n",
      "476\n",
      "squeezenet_epoch_0_output {0: 101, 1: 31, 2: 259, 3: 38, 4: 47}\n",
      "755\n",
      "476\n",
      "squeezenet_epoch_0_output {0: 101, 1: 31, 2: 259, 3: 38, 4: 47}\n",
      "755\n",
      "476\n",
      "squeezenet_epoch_0_output {0: 101, 1: 31, 2: 259, 3: 38, 4: 47}\n"
     ]
    }
   ],
   "source": [
    "arrs_cifar10 = func('cifar10')\n",
    "arrs_cifar100 = func('cifar100')\n",
    "arrs_cifar100super = func('cifar100super')\n",
    "arrs_adience = func('adience')\n",
    "arrs_utkface = func('utkface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/NS/twitter-7/work/vnanda/miniconda3/envs/adv_disparity/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in greater\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/NS/twitter-7/work/vnanda/miniconda3/envs/adv_disparity/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in greater\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 54 43 54\n",
      "83.33333333333334 79.62962962962963\n",
      "49 66 48 66\n",
      "74.24242424242425 72.72727272727273\n",
      "45 60 46 60\n",
      "75.0 76.66666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/NS/twitter-7/work/vnanda/miniconda3/envs/adv_disparity/lib/python3.7/site-packages/ipykernel_launcher.py:82: RuntimeWarning: invalid value encountered in greater\n",
      "/NS/twitter-7/work/vnanda/miniconda3/envs/adv_disparity/lib/python3.7/site-packages/ipykernel_launcher.py:84: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323 600 324 600\n",
      "53.833333333333336 54.0\n",
      "79 120 80 120\n",
      "65.83333333333333 66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "agg_df, total_df = 0,0\n",
    "agg_cw, total_cw = 0,0\n",
    "\n",
    "models = ['adience_classifier','resnet','alexnet','vgg','densenet','squeezenet']\n",
    "best_arr_1, frst_arr_1 = plot_ds('Adience',models, dataset_to_labels, df)\n",
    "best_arr_2, frst_arr_2 = plot_ds('Adience',models, sensitive_attrs, df)\n",
    "\n",
    "best_arr_1_cw, frst_arr_1_cw = plot_ds('Adience',models, dataset_to_labels, cw)\n",
    "best_arr_2_cw, frst_arr_2_cw = plot_ds('Adience',models, sensitive_attrs, cw)\n",
    "\n",
    "agg_df += np.sum(np.equal(best_arr_1.T > 0, arrs_adience[0]>0))\n",
    "total_df += np.prod(best_arr_1.shape)\n",
    "agg_df += np.sum(np.equal(best_arr_2.T > 0, arrs_adience[1]>0))\n",
    "total_df += np.prod(best_arr_2.shape)\n",
    "\n",
    "agg_cw += np.sum(np.equal(best_arr_1_cw.T > 0, arrs_adience[0]>0))\n",
    "total_cw += np.prod(best_arr_1.shape)\n",
    "agg_cw += np.sum(np.equal(best_arr_2_cw.T > 0, arrs_adience[1]>0))\n",
    "total_cw += np.prod(best_arr_2.shape)\n",
    "\n",
    "print(agg_df,total_df,agg_cw,total_cw)\n",
    "print(agg_df/total_df*100,agg_cw/total_cw*100)\n",
    "\n",
    "\n",
    "agg_df, total_df = 0,0\n",
    "agg_cw, total_cw = 0,0\n",
    "\n",
    "models = ['utk_classifier','resnet','alexnet','vgg','densenet','squeezenet']\n",
    "best_arr_1, frst_arr_1 = plot_ds('utkface_race',models, dataset_to_labels, df)\n",
    "best_arr_2, frst_arr_2 = plot_ds('utkface_gender',models, sensitive_attrs, df)\n",
    "best_arr_3, frst_arr_3 = plot_ds('utkface_race',models, sensitive_attrs, df)\n",
    "\n",
    "best_arr_1_cw, frst_arr_1_cw = plot_ds('utkface_race',models, dataset_to_labels, cw)\n",
    "best_arr_2_cw, frst_arr_2_cw = plot_ds('utkface_gender',models, sensitive_attrs, cw)\n",
    "best_arr_3_cw, frst_arr_3_cw = plot_ds('utkface_race',models, sensitive_attrs, cw)\n",
    "\n",
    "agg_df += np.sum(np.equal(best_arr_1.T > 0, arrs_utkface[0]>0))\n",
    "total_df += np.prod(best_arr_1.shape)\n",
    "agg_df += np.sum(np.equal(best_arr_2[0] > 0, arrs_utkface[1][:,1]>0))\n",
    "total_df += np.prod(best_arr_2.shape)\n",
    "agg_df += np.sum(np.equal(best_arr_3.T > 0, arrs_utkface[2]>0))\n",
    "total_df += np.prod(best_arr_3.shape)\n",
    "\n",
    "agg_cw += np.sum(np.equal(best_arr_1_cw.T > 0, arrs_utkface[0]>0))\n",
    "total_cw += np.prod(best_arr_1_cw.shape)\n",
    "agg_cw += np.sum(np.equal(best_arr_2_cw[0] > 0, arrs_utkface[1][:,1]>0))\n",
    "total_cw += np.prod(best_arr_2_cw.shape)\n",
    "agg_cw += np.sum(np.equal(best_arr_3_cw.T > 0, arrs_utkface[2]>0))\n",
    "total_cw += np.prod(best_arr_3_cw.shape)\n",
    "\n",
    "print(agg_df,total_df,agg_cw,total_cw)\n",
    "print(agg_df/total_df*100,agg_cw/total_cw*100)\n",
    "\n",
    "\n",
    "agg_df, total_df = 0,0\n",
    "agg_cw, total_cw = 0,0\n",
    "\n",
    "models = ['deep_cnn','pyramidnet','resnet','vgg','densenet','squeezenet']\n",
    "models_full = ['deep_cnn','pyramidnet_alpha_64_depth_110','resnet','vgg','densenet','squeezenet']\n",
    "best_arr_1, frst_arr_1 = plot_ds('CIFAR10',models_full, dataset_to_labels, df)\n",
    "\n",
    "best_arr_1_cw, frst_arr_1_cw = plot_ds('CIFAR10',models_full, dataset_to_labels, cw)\n",
    "\n",
    "agg_df += np.sum(np.equal(best_arr_1.T > 0, arrs_cifar10[0]>0))\n",
    "total_df += np.prod(best_arr_1.shape)\n",
    "agg_cw += np.sum(np.equal(best_arr_1_cw.T > 0, arrs_cifar10[0]>0))\n",
    "total_cw += np.prod(best_arr_1.shape)\n",
    "\n",
    "print(agg_df,total_df,agg_cw,total_cw)\n",
    "print(agg_df/total_df*100,agg_cw/total_cw*100)\n",
    "\n",
    "\n",
    "agg_df, total_df = 0,0\n",
    "agg_cw, total_cw = 0,0\n",
    "\n",
    "models = ['deep_cnn','pyramidnet','resnet','vgg','densenet','squeezenet']\n",
    "models_full = ['deep_cnn_cifar100','pyramidnet_alpha_48_depth_164_bottleneck','resnet','vgg','densenet','squeezenet']\n",
    "best_arr_1, frst_arr_1 = plot_ds('CIFAR100',models_full, dataset_to_labels, df)\n",
    "\n",
    "best_arr_1_cw, frst_arr_1_cw = plot_ds('CIFAR100',models_full, dataset_to_labels, cw)\n",
    "\n",
    "agg_df += np.sum(np.equal(best_arr_1.T > 0, arrs_cifar100[0]>0))\n",
    "total_df += np.prod(best_arr_1.shape)\n",
    "agg_cw += np.sum(np.equal(best_arr_1_cw.T > 0, arrs_cifar100[0]>0))\n",
    "total_cw += np.prod(best_arr_1.shape)\n",
    "\n",
    "print(agg_df,total_df,agg_cw,total_cw)\n",
    "print(agg_df/total_df*100,agg_cw/total_cw*100)\n",
    "\n",
    "\n",
    "agg_df, total_df = 0,0\n",
    "agg_cw, total_cw = 0,0\n",
    "\n",
    "models = ['deep_cnn','pyramidnet','resnet','vgg','densenet','squeezenet']\n",
    "models_full = ['deep_cnn_cifar100','pyramidnet_alpha_48_depth_164_bottleneck','resnet','vgg','densenet','squeezenet']\n",
    "best_arr_1, frst_arr_1 = plot_ds('CIFAR100super',models_full, dataset_to_labels, df)\n",
    "\n",
    "best_arr_1_cw, frst_arr_1_cw = plot_ds('CIFAR100super',models_full, dataset_to_labels, cw)\n",
    "\n",
    "agg_df += np.sum(np.equal(best_arr_1.T > 0, arrs_cifar100super[0]>0))\n",
    "total_df += np.prod(best_arr_1.shape)\n",
    "agg_cw += np.sum(np.equal(best_arr_1_cw.T > 0, arrs_cifar100super[0]>0))\n",
    "total_cw += np.prod(best_arr_1.shape)\n",
    "\n",
    "print(agg_df,total_df,agg_cw,total_cw)\n",
    "print(agg_df/total_df*100,agg_cw/total_cw*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
