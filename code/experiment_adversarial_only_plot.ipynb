{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this to make adversarial plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import sys, os, glob\n",
    "import time\n",
    "import operator\n",
    "import itertools\n",
    "import joblib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import foolbox\n",
    "import getopt\n",
    "sys.path.insert(0, \"../util\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import model\n",
    "\n",
    "%run adversarial.ipynb\n",
    "\n",
    "## Load other helper functions and classes\n",
    "from pytorch_data_loader import PytorchLoader\n",
    "import helper as hp\n",
    "from data_loader import UTKFace, Adience, CIFAR10\n",
    "from adversarial import Attack, AttackV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHASES = ['train', 'test']\n",
    "batch_size = 500\n",
    "learning_rate = 0.0005\n",
    "aggregate_coeff = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'utkface_race'\n",
    "gpu = 0\n",
    "model_name = 'squeezenet'\n",
    "epochs = ['best']\n",
    "taus = [None]\n",
    "alphas = [None]\n",
    "with_regularization=False\n",
    "sigmoid_approx=False\n",
    "probabilities=True\n",
    "paper_friendly_plots=True\n",
    "\n",
    "COLORS = ['blue', 'red', 'green', 'orange', 'magenta', 'yellow', 'black', 'grey', 'cyan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:{}'.format(gpu))\n",
    "\n",
    "attack_names = ['DeepFool', 'CarliniWagner']\n",
    "\n",
    "ds_obj, datasets, data_loaders = \\\n",
    "    hp.get_data_loder_objects(dataset, PHASES, **hp.get_loader_kwargs(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_adversarial_objects(folder, epoch, ds_obj, device):\n",
    "    object_paths = glob.glob(\"{}/*_epoch_{}*\".format(folder, epoch))\n",
    "    objects = []\n",
    "    # predicted = []\n",
    "    image_ids = []\n",
    "    for obj in object_paths:\n",
    "        image_ids.append(int(obj.split('/')[-1].rstrip('.pkl').split('_')[0]))\n",
    "        adv_obj = joblib.load(obj)\n",
    "        # tiled_mean = np.tile(\n",
    "        #     ds_obj.data_transform.transforms[-1].mean, (adv_obj.image.shape[1], adv_obj.image.shape[2], 1)).T\n",
    "        # tiled_std = np.tile(\n",
    "        #     ds_obj.data_transform.transforms[-1].std, (adv_obj.image.shape[1], adv_obj.image.shape[2], 1)).T\n",
    "        # processed_image = torch.tensor((adv_obj.image - tiled_mean)/tiled_std)\n",
    "        # model_op = model.model_ft(processed_image.view((1,) + processed_image.size()).to(device))\n",
    "        # _, preds = torch.max(model_op, 1)\n",
    "        # predicted.append(preds.cpu().numpy()[0])\n",
    "        objects.append(adv_obj)\n",
    "    return np.array(image_ids), objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_differences(adv_image_ids, all_adv_images, sensitive_attr, ds_obj):\n",
    "    \"\"\"\n",
    "    Give sensitive_attr as all 1 to get all image differences in minority_differences\n",
    "    Conversely, give sensitive_attr as all 0 to get all image differences in minority_differences\n",
    "    \"\"\"\n",
    "    minority_differences, majority_differences = [], []\n",
    "    for idx, img_id in enumerate(adv_image_ids):\n",
    "        processed_img = ds_obj.get_image('test', int(img_id))\n",
    "        raw_img = hp.inverse_transpose_images(processed_img.numpy(), ds_obj.data_transform)\n",
    "        adv_img = np.moveaxis(all_adv_images[idx], 0, -1) # channels first, non normalized\n",
    "        if sensitive_attr[idx] == 1:\n",
    "            minority_differences.append(np.linalg.norm(raw_img - adv_img))\n",
    "        else:\n",
    "            majority_differences.append(np.linalg.norm(raw_img - adv_img))\n",
    "            \n",
    "    return minority_differences, majority_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_differences_individual(adv_image_ids, all_adv_images, ds_obj):\n",
    "    differences = []\n",
    "    for idx, img_id in enumerate(adv_image_ids):\n",
    "        processed_img = ds_obj.get_image('test', int(img_id))\n",
    "        raw_img = hp.inverse_transpose_images(processed_img.numpy(), ds_obj.data_transform)\n",
    "        adv_img = np.moveaxis(all_adv_images[idx], 0, -1) # channels first, non normalized\n",
    "        differences.append(np.linalg.norm(raw_img - adv_img))\n",
    "            \n",
    "    return differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_paper_friendly_plots_params():\n",
    "    plt.style.use('seaborn-paper')\n",
    "    plt.rcParams['font.size'] = 10\n",
    "    plt.rcParams['axes.labelsize'] = 22\n",
    "    plt.rcParams['axes.labelweight'] = 'bold'\n",
    "    plt.rcParams['axes.titlesize'] = 15\n",
    "    plt.rcParams['axes.linewidth'] = 1.25\n",
    "    plt.rcParams['xtick.labelsize'] = 16\n",
    "    plt.rcParams['ytick.labelsize'] = 16\n",
    "    plt.rcParams['legend.fontsize'] = 20\n",
    "    plt.rcParams['figure.titlesize'] = 22\n",
    "    plt.rcParams['lines.linewidth'] = 4.0\n",
    "    plt.rcParams['grid.color'] = 'grey'\n",
    "    plt.rcParams['grid.linestyle'] = '--'\n",
    "    plt.rcParams['grid.linewidth'] = 0.25\n",
    "    plt.rcParams['figure.dpi'] = 50\n",
    "    plt.rcParams['savefig.dpi'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../utkface_race/adversarial_images/squeezenet/DeepFool\n",
      "3160\n",
      "['asian' 'black' 'indian' 'other' 'white']\n",
      "../utkface_race/adversarial_images/squeezenet/CarliniWagner\n",
      "3160\n",
      "['asian' 'black' 'indian' 'other' 'white']\n"
     ]
    }
   ],
   "source": [
    "for epoch in epochs:\n",
    "    for (tau_idx, tau), (alpha_idx, alpha) in itertools.product(*[enumerate(taus), enumerate(alphas)]):\n",
    "        regularization_params = {'tau': tau, 'alpha': alpha, 'sigmoid_approx': sigmoid_approx, \n",
    "            'probabilities': probabilities, 'device': device}\n",
    "        model_to_load = model.DNN(model_name=model_name, num_classes=ds_obj.num_classes(), \n",
    "            learning_rate=learning_rate, aggregate_coeff=aggregate_coeff,\n",
    "            with_regularization=with_regularization, \n",
    "            regularization_params=regularization_params)\n",
    "\n",
    "        # filename = '{}_{}_epoch_{}_lr_{}.pth'.format(model_to_load.model_name, model_to_load.criterion._get_name(), \n",
    "        #     epoch, learning_rate)\n",
    "        # model_to_load.model_ft.load_state_dict(torch.load('../{}/model_weights/{}'.format(ds_obj.name, filename),\n",
    "        #                                          map_location=device))\n",
    "        # model_to_load.model_ft.eval()\n",
    "        # print ('Loaded weights from: ../{}/model_weights/{}'.format(ds_obj.name, filename))\n",
    "\n",
    "        complete_model_name = '{}_{}'.format(model_to_load.model_name, model_to_load.criterion._get_name()) \\\n",
    "            if not isinstance(model_to_load.criterion, nn.CrossEntropyLoss) else model_to_load.model_name\n",
    "\n",
    "        for attack_name in attack_names:\n",
    "\n",
    "            adv_folder = '../{}/adversarial_images/{}/{}'.format(ds_obj.name, \n",
    "                complete_model_name, attack_name)\n",
    "            adv_image_ids, all_adv_objs = \\\n",
    "                load_adversarial_objects(folder=adv_folder, epoch=epoch, ds_obj=ds_obj, device=device)\n",
    "            all_images_adversarial = np.array([x.image for x in all_adv_objs])\n",
    "\n",
    "            print (adv_folder)\n",
    "            print (len(glob.glob(\"{}/*_epoch_{}*\".format(adv_folder, epoch))))\n",
    "\n",
    "            if 'cifar' in ds_obj.name.lower():\n",
    "                if ds_obj.name.lower() == 'cifar10':\n",
    "                    sensitive_attrs, sensitive_attrs_names = [], []\n",
    "                    for cname in ds_obj.classes:\n",
    "                        sensitive_attrs_names.append(cname)\n",
    "                        sensitive_attrs.append(np.array([1 if ds_obj.classes[ds_obj.test_labels[int(img_id)]] == \\\n",
    "                                                         cname else 0 for img_id in adv_image_ids]))\n",
    "                else:\n",
    "                    sensitive_attrs = [np.array(\n",
    "                        [1 if ds_obj.classes[ds_obj.test_labels[int(img_id)]] == \\\n",
    "                            ds_obj.name.split('_')[-1].lower() \\\n",
    "                        else 0 for img_id in adv_image_ids])]\n",
    "                    sensitive_attrs_names = [ds_obj.name.lower().split('_')[-1]]\n",
    "            else:\n",
    "                attr = ds_obj.name.lower().split('_')[-1]\n",
    "                sensitive_attrs = [np.array([\n",
    "                    ds_obj.get_image_protected_id_to_label(\n",
    "                        ds_obj.get_image_protected_class('test', int(img_id), attr=attr), attr=attr) \\\n",
    "                                        for img_id in adv_image_ids])]\n",
    "                sensitive_attrs_names = ['Black' if attr == 'race' else 'Female']\n",
    "#                 sensitive_attrs_names = []\n",
    "\n",
    "#             majority_differences, minority_differences = [], []\n",
    "#             for sensitive_attr in sensitive_attrs:\n",
    "#                 minority_difference, majority_difference = \\\n",
    "#                     image_differences(adv_image_ids, all_images_adversarial, sensitive_attr, ds_obj)\n",
    "#                 majority_differences.append(majority_difference)\n",
    "#                 minority_differences.append(minority_difference)\n",
    "            \n",
    "            hp.create_dir(\"plots/{}\".format(ds_obj.name))\n",
    "            hp.create_dir(\"plots/{}/{}\".format(ds_obj.name, model_to_load.model_name))\n",
    "            hp.create_dir(\"plots/{}/{}/{}\".format(ds_obj.name, model_to_load.model_name, attack_name))\n",
    "            dir_to_save = \"plots/{}/{}/{}\".format(ds_obj.name, model_to_load.model_name, attack_name)\n",
    "            if paper_friendly_plots:\n",
    "                set_paper_friendly_plots_params()\n",
    "            # plotting all sens attrs on the same plot\n",
    "            for sens_attr, sens_attr_name in zip(sensitive_attrs, sensitive_attrs_names):\n",
    "                differences_sens_attrs = []\n",
    "                labels = []\n",
    "                print (np.unique(sens_attr))\n",
    "                for attr_label in np.unique(sens_attr):\n",
    "                    differences_sens_attrs.append(\n",
    "                        image_differences_individual(adv_image_ids[sens_attr == attr_label], \n",
    "                                                     all_images_adversarial[sens_attr == attr_label], ds_obj))\n",
    "#                     labels.append(ds_obj.get_image_protected_id_to_label(attr_id, attr=attr))\n",
    "                    labels.append(attr_label)\n",
    "                \n",
    "                taus = np.linspace(np.min([np.min(x) for x in differences_sens_attrs]), \n",
    "                                   np.max([np.max(x) for x in differences_sens_attrs]), 2000)\n",
    "                \n",
    "                fig = plt.figure()\n",
    "                if not paper_friendly_plots:\n",
    "                    fig.suptitle(r'fraction $d_\\theta > \\tau$ for {}'.format(ds_obj.name), fontsize=20)\n",
    "                ax = fig.add_subplot(111)\n",
    "                ax.set_xlabel('Distance to Adv. Sample' + r' ($\\tau$)')\n",
    "                ax.set_ylabel(r'$ \\widehat{I^\\tau_s} $')\n",
    "                \n",
    "                for (idx, label), difference in zip(enumerate(labels), differences_sens_attrs):\n",
    "                    frac_greater_than_tau = np.array([np.sum(difference > t) / len(difference) for t in taus])\n",
    "                    ax.plot(taus, frac_greater_than_tau, color=COLORS[idx], label=label, alpha=0.5)\n",
    "                \n",
    "                if paper_friendly_plots and not 'carliniwagner' in attack_name.lower():\n",
    "                    plt.legend()\n",
    "                elif not paper_friendly_plots:\n",
    "                    plt.legend()\n",
    "\n",
    "                extension = 'png' if not paper_friendly_plots else 'pdf'\n",
    "                filename = '{}_inv_cdf'.format(model_to_load.criterion._get_name()) \\\n",
    "                    if not isinstance(model_to_load.criterion, nn.CrossEntropyLoss) else \\\n",
    "                        'inv_cdf_{}_all_on_one'.format(sens_attr_name)\n",
    "                plt.savefig('{}/{}.{}'.format(dir_to_save, filename, extension), bbox_inches='tight')\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                \n",
    "                    \n",
    "\n",
    "            # print (minority_difference, majority_difference)\n",
    "\n",
    "#             hp.create_dir(\"plots/{}\".format(ds_obj.name))\n",
    "#             hp.create_dir(\"plots/{}/{}\".format(ds_obj.name, model_to_load.model_name))\n",
    "#             hp.create_dir(\"plots/{}/{}/{}\".format(ds_obj.name, model_to_load.model_name, attack_name))\n",
    "\n",
    "#             dir_to_save = \"plots/{}/{}/{}\".format(ds_obj.name, model_to_load.model_name, attack_name)\n",
    "\n",
    "#             taus = np.linspace(0.0, 0.5, 2000)\n",
    "# #             taus = np.linspace(0.0, 2.0, 2000) # if 'deepfool' in attack_name.lower() else np.linspace(2.9, 3.1, 2000)\n",
    "\n",
    "#             for minority_difference, majority_difference, sensitive_attr_name in zip(minority_differences, majority_differences, sensitive_attrs_names):\n",
    "#                 frac_greater_than_tau_majority = np.array([np.sum(majority_difference > t) / len(majority_difference) for t in taus])\n",
    "#                 frac_greater_than_tau_minority = np.array([np.sum(minority_difference > t) / len(minority_difference) for t in taus])\n",
    "\n",
    "#                 if paper_friendly_plots:\n",
    "#                     set_paper_friendly_plots_params()\n",
    "\n",
    "#                 fig = plt.figure()\n",
    "#                 if not paper_friendly_plots:\n",
    "#                     fig.suptitle(r'fraction $d_\\theta > \\tau$ for {}'.format(ds_obj.name), fontsize=20)\n",
    "#                 ax = fig.add_subplot(111)\n",
    "#                 ax.plot(taus, frac_greater_than_tau_majority, color='blue', label='Other Classes')\n",
    "#                 ax.plot(taus, frac_greater_than_tau_minority, color='red', label='{}'.format(sensitive_attr_name))\n",
    "#                 ax.set_xlabel('Distance to Adv. Sample' + r' ($\\tau$)')\n",
    "#                 ax.set_ylabel(r'$ \\widehat{I^\\tau_s} $')\n",
    "#                 plt.legend()\n",
    "\n",
    "#                 extension = 'png' if not paper_friendly_plots else 'pdf'\n",
    "#                 filename = '{}_inv_cdf'.format(model_to_load.criterion._get_name()) \\\n",
    "#                     if not isinstance(model_to_load.criterion, nn.CrossEntropyLoss) else \\\n",
    "#                         'inv_cdf_{}'.format(sensitive_attr_name)\n",
    "#                 plt.savefig('{}/{}.{}'.format(dir_to_save, filename, extension), bbox_inches='tight')\n",
    "#                 plt.show()\n",
    "#                 plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
